# EXP 5: COMPARATIVE ANALYSIS OF DIFFERENT TYPES OF PROMPTING PATTERNS  

**NAME:** NAVEEN K  
**REGISTER NUMBER:** 212223060184  

---

## Aim  
To analyze and compare how different prompting styles (general/unstructured vs. structured/clear) influence ChatGPT’s responses across multiple use cases. The focus is on response quality, correctness, and depth.  

---

## AI Tools Required  
- ChatGPT (or equivalent LLM)  
- Document editor to record responses  
- Evaluation rubric (quality, accuracy, depth)  

---

## Explanation  

### Defining Prompt Types  
- **Naïve Prompt:** A simple, broad instruction without much detail.  
- **Basic Prompt:** A refined prompt with clarity, structure, and explicit requirements.  

---

## Procedure  
1. For each scenario, prepare two prompts: one naïve and one basic.  
2. Collect responses for both prompts.  
3. Evaluate responses based on quality, accuracy, and depth.  
4. Compare results.  

---

## Test Scenarios  

### Scenario 1: Creative Story Generation  
- **Naïve Prompt:** “Write a story.”  
- **Basic Prompt:** “Write a short story (150–200 words) about a young engineer who builds a solar-powered car for her village. The story should have a beginning, a conflict, and a resolution.”  

**Observation:**  
- Naïve: Generic story, often lacking structure.  
- Basic: Focused, engaging, and well-organized plot.  

---

### Scenario 2: Factual Question  
- **Naïve Prompt:** “Tell me about electricity.”  
- **Basic Prompt:** “Explain electricity in 3–4 lines, including its definition, sources, and daily life applications. Keep it simple for a high school student.”  

**Observation:**  
- Naïve: Too broad, scattered response.  
- Basic: Concise, accurate, and audience-friendly explanation.  

---

### Scenario 3: Summarization  
- **Naïve Prompt:** “Summarize AI.”  
- **Basic Prompt:** “Summarize Artificial Intelligence in 5 sentences, covering its definition, major types, important applications, and relevance in modern technology.”  

**Observation:**  
- Naïve: Short and vague.  
- Basic: Clear, structured, and covers essential points.  

---

### Scenario 4: Advice / Recommendation  
- **Naïve Prompt:** “Give me advice.”  
- **Basic Prompt:** “Provide 3 useful tips for a college student to manage time effectively during exam preparation.”  

**Observation:**  
- Naïve: Random and unfocused.  
- Basic: Practical, specific, and relevant suggestions.  

---

## Comparative Table  

| Scenario              | Naïve Prompt Response            | Basic Prompt Response                    | Quality   | Accuracy | Depth   |  
|-----------------------|----------------------------------|------------------------------------------|-----------|----------|---------|  
| Story Generation      | Generic, unstructured            | Detailed story with clear resolution      | Medium    | Medium   | Medium  |  
| Factual Question      | Overly broad                     | Concise, clear, accurate                  | High      | High     | High    |  
| Summarization         | Vague, incomplete                | Organized and comprehensive               | Medium    | High     | High    |  
| Advice/Recommendation | Random, general                  | Focused, 3 clear tips                     | Medium    | High     | High    |  

---

## Analysis  
- **Quality:** Always better with structured prompts.  
- **Accuracy:** Naïve prompts led to vague outputs, while basic prompts ensured correctness.  
- **Depth:** Basic prompts encouraged richer, context-sensitive responses.  
- **Key Insight:** Naïve prompts allow freedom but lack reliability. Basic prompts consistently produce more useful outputs.  

---

## Summary of Findings  
- Clear prompts significantly improve the quality and usefulness of outputs.  
- Naïve prompts generally result in incomplete or generic answers.  
- Structured prompts provide focused, accurate, and actionable responses.  
- Best practice: Always include context, constraints, and required format in prompts.  

---

## Output  
- Naïve prompts → Generic, loosely structured, sometimes vague responses.  
- Basic prompts → Context-rich, accurate, and audience-aware responses.  
- In all scenarios (story, factual Q&A, summarization, advice), structured prompts performed better across quality, accuracy, and depth.  

---

## Result  
The experiment was successfully carried out, and it was observed that structured prompts consistently outperform naïve prompts in terms of quality, accuracy, and depth of responses.  
